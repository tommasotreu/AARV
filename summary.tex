We have tried to provide a succinct review of gravitational time delays as
a tool for measuring cosmological parameters. In addition to giving a
brief introduction to the theoretical underpinnings of the method, the
review discusses the past history of the field, before turning to
present day accomplishments and the challenges ahead. The main points
of this review can be summarized as follows:

\begin{enumerate}
\item From a theoretical point of view gravitational time delays are a
clean and well understood probe of cosmic acceleration. Conceptually,
each time delay measurement provides a direct one step measurement of
absolute distance. The typical redshifts of deflectors and sources span
the range between $z\sim2$ and today, covering the era of cosmic time
during which dark energy rose to prominence.
\item Even though the potential cosmological application of strongly
lensed, time-variable sources was recognized as early as 1964, it took
decades for the method to come to practical fruition. Two sets of
challenges have been overcome over the past 15 years. Observationally, the
main challenge has been organizing long term monitoring campaigns and
mustering the range of resources required to constrain accurate mass
models. Theoretically, the main challenge consisted of learning how to
exploit the available information to construct lens models with
realistic estimates of the uncertainties.
\item It has been demonstrated through blind measurements that each
individual system can deliver a measurement of absolute distance to
about 6-7\% total uncertainty, given current data quality.   The power of
the method is currently limited by the number of systems with
well-measured time delays and sufficient ancillary data to carry out
detailed modeling ($\lesssim10$ at the time of writing).
\item Systematic searches for strongly lensed quasars are under way and
should be able to increase the cosmographic sample size by more than an
order of magnitude in the next decade. With improvements in follow-up image
resolution and spatially resolved spectroscopy as well, we can aspire to
to sub-percent precision in the Hubble constant by the
middle of the next decade.
\item Before LSST, dedicated monitoring campaigns will the required to
measure each time delay; LSST can potentially alter the landscape, if
it can deliver hundreds of time delays from the survey data themselves.
\item Throughout the next decade a promising strategy to deliver the
available precision will consist of obtaining a
range of high quality follow-up data in order to minimize the
uncertainty per system. These include: high resolution imaging from
space or with adaptive optics; redshifts, stellar velocity dispersions,
and spatially resolved kinematics of the deflectors from the James Webb
Space Telescope or large and extremely large ground based telescopes.
\item  In the LSST era it will be possible, and perhaps desirable,  to
employ a mixed strategy where large numbers of systems with relatively
scant follow-up data can be analyzed with hierarchical models based on
priors based on the in depth analysis of smaller precursor datasets.
\item {\bf PJM: New conclusion, about the need to test our ability to
mitigate systematics.} Work is still needed to understand, quantify and
mitigate against the systematic errors in  the method, in order for this
precision to be realized and an accurate cosmological measurement made.
Extensive parameter recovery tests on realistic simulated monitoring,
high resolution imaging, spatially resolved spectroscopy, and field weak
lensing and photometric data will be essential to test whether the
residual biases are sub-dominant or otherwise.
\end{enumerate}

% \textbf{TT: The above may be less concise than we want it to be. Free free to have a go at condensing it.}

% PJM: The following sounded a bit high falutin to me!
%
% In conclusion,
% it would be presumptuous to forecast how and when we are
% going to understand the deep mystery of cosmic acceleration, but it
% would be foolish not to try by means of
% as theoretically sound and
% cost-effective a tool as gravitational time delays.
%
% How about this instead?
In gravitational time delays we have a theoretically sound,
experimentally competitive, and cost-effective cosmographic tool.
%
Studying lensed
quasars will allow us, in the worst-case scenario, to learn much about
the universe:lensed quasars can be used to study a variety of topics
ranging from the nature of dark matter
\citep{Metcalf:2005p1203,Xu++09,Veg++14,Nie++14} to the physics of
black hole acretion disks \citep{PMK08,Blackburne:2010p6600}, to the
initial mass function of stars \citep{Sch++14}. If nature is kind
enough to provide us with the best-case scenario, time delay cosmography
will be able to
% PJM: Note "contribution," DE science will be a joint effort...
make a valuable contribution to our evolving understanding of the
fundamental nature of space time.
